#!/usr/bin/env python3

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent))

from fast_saturn_parser import FastSaturnParser
from bs4 import BeautifulSoup
import requests

def debug_407_detailed():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–Ω–æ–π 407‚ÇΩ"""
    
    # –û–¥–∏–Ω –ø—Ä–æ–±–ª–µ–º–Ω—ã–π SKU –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    sku = "216212"
    
    print(f"üî¨ –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê SKU: {sku}")
    print("=" * 50)
    
    parser = FastSaturnParser()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    search_url = f"https://nnv.saturn.net/catalog/?sp%5Bname%5D=1&sp%5Bartikul%5D=1&search=&s={sku}"
    print(f"üîó –ü–æ–∏—Å–∫–æ–≤—ã–π URL: {search_url}")
    
    response = parser.session.get(search_url, timeout=10)
    if response.status_code != 200:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {response.status_code}")
        return
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
    page_text = soup.get_text()
    if "–Ω–∞–π–¥–µ–Ω–æ:" in page_text.lower() and "—Ç–æ–≤–∞—Ä" in page_text.lower():
        print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞")
        
        import re
        from urllib.parse import urljoin
        
        product_links = soup.find_all('a', href=re.compile(r'/catalog/[^/]+/[^/]+/$'))
        print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã: {len(product_links)}")
        
        for i, link in enumerate(product_links):
            link_text = link.get_text(strip=True).lower()
            href = link.get('href')
            
            print(f"\n--- –°–°–´–õ–ö–ê {i+1} ---")
            print(f"–¢–µ–∫—Å—Ç: '{link_text}'")
            print(f"URL: {href}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏–µ –ø–æ–∏—Å–∫–∞
            if (sku in link_text or f"—Ç–æ–≤-{sku}" in link_text):
                print(f"‚úÖ –°–û–í–ü–ê–î–ï–ù–ò–ï! SKU '{sku}' –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ —Å—Å—ã–ª–∫–∏")
                
                if not href.startswith('http'):
                    product_url = urljoin("https://nnv.saturn.net", href)
                else:
                    product_url = href
                
                print(f"üîó –ü–æ–ª–Ω—ã–π URL —Ç–æ–≤–∞—Ä–∞: {product_url}")
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
                product_response = parser.session.get(product_url, timeout=10)
                if product_response.status_code == 200:
                    product_soup = BeautifulSoup(product_response.content, 'html.parser')
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞
                    page_content = product_soup.get_text()
                    expected_article = f"—Ç–æ–≤-{sku}"
                    
                    print(f"üîç –ò—â–µ–º –∞—Ä—Ç–∏–∫—É–ª '{expected_article}' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞...")
                    
                    if expected_article in page_content:
                        print("‚úÖ –ê–†–¢–ò–ö–£–õ –ù–ê–ô–î–ï–ù –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞")
                    else:
                        print("‚ùå –ê–†–¢–ò–ö–£–õ –ù–ï –ù–ê–ô–î–ï–ù –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞")
                        print("üîç –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π '—Ç–æ–≤-' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
                        
                        # –ò—â–µ–º –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                        import re
                        articles = re.findall(r'—Ç–æ–≤-\d+', page_content)
                        if articles:
                            unique_articles = list(set(articles))
                            print(f"   –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã: {unique_articles}")
                        else:
                            print("   –ê—Ä—Ç–∏–∫—É–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–Ω—É
                    price_elements = product_soup.find_all(attrs={'data-price': True})
                    if price_elements:
                        price_value = price_elements[0].get('data-price')
                        print(f"üí∞ –¶–µ–Ω–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {price_value}‚ÇΩ")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                        for tag in ['h1', 'h2', 'title']:
                            title_elem = product_soup.find(tag)
                            if title_elem:
                                name = title_elem.get_text(strip=True)
                                if len(name) > 10:
                                    print(f"üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {name}")
                                    break
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    with open(f"debug_product_{sku}.html", "w", encoding="utf-8") as f:
                        f.write(str(product_soup))
                    print(f"üíæ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ debug_product_{sku}.html")
                    
                    break
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞: {product_response.status_code}")
            else:
                print(f"‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å SKU '{sku}'")
    else:
        print("‚ùå –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

if __name__ == "__main__":
    debug_407_detailed()

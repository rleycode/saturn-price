#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
import re
import time

def debug_product_007556():
    """–û—Ç–ª–∞–¥–∫–∞ –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–∞ 007556 –Ω–∞ Saturn"""
    
    sku = "007556"
    article_with_prefix = f"—Ç–æ–≤-{sku}"
    
    print(f"üîç –û–¢–õ–ê–î–ö–ê –ü–û–ò–°–ö–ê –¢–û–í–ê–†–ê {article_with_prefix}")
    print("=" * 50)
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    })
    
    # –ú–ï–¢–û–î 1: –ü–æ–∏—Å–∫ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö —Ç–æ–≤–∞—Ä–æ–≤
    print("\nüì¶ –ú–ï–¢–û–î 1: –ü–æ–∏—Å–∫ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö —Ç–æ–≤–∞—Ä–æ–≤")
    print("-" * 30)
    
    search_url = f"https://saturn-r.ru/search/?q={sku}"
    print(f"URL –ø–æ–∏—Å–∫–∞: {search_url}")
    
    try:
        response = session.get(search_url, timeout=10)
        print(f"–°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Ç–æ–≤–∞—Ä–æ–≤
            product_containers = soup.find_all('div', class_='h_s_list_categor_item_wrap')
            print(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤: {len(product_containers)}")
            
            for i, container in enumerate(product_containers[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                article_elem = container.find('p', class_='h_s_list_categor_item_articul')
                name_elem = container.find('a', class_='h_s_list_categor_item')
                
                if article_elem and name_elem:
                    found_article = article_elem.get_text(strip=True)
                    found_name = name_elem.get_text(strip=True)
                    print(f"  {i+1}. {found_article}: {found_name}")
                    
                    if found_article == article_with_prefix:
                        print(f"  ‚úÖ –ù–ê–ô–î–ï–ù! {found_article}")
                        return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ HTTP: {response.status_code}")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ú–µ—Ç–æ–¥–∞ 1: {e}")
    
    # –ú–ï–¢–û–î 2: –ü–æ–∏—Å–∫ –ø–æ —Å—Å—ã–ª–∫–∞–º –Ω–∞ —Ç–æ–≤–∞—Ä—ã
    print("\nüîó –ú–ï–¢–û–î 2: –ü–æ–∏—Å–∫ –ø–æ —Å—Å—ã–ª–∫–∞–º –Ω–∞ —Ç–æ–≤–∞—Ä—ã")
    print("-" * 30)
    
    try:
        response = session.get(search_url, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
            product_links = soup.find_all('a', href=re.compile(r'/catalog/[^/]+/[^/]+/$'))
            print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã: {len(product_links)}")
            
            for i, link in enumerate(product_links[:3]):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3
                product_url = "https://saturn-r.ru" + link['href']
                print(f"  {i+1}. –ü—Ä–æ–≤–µ—Ä—è–µ–º: {product_url}")
                
                try:
                    product_response = session.get(product_url, timeout=10)
                    if product_response.status_code == 200:
                        product_soup = BeautifulSoup(product_response.content, 'html.parser')
                        
                        # –ò—â–µ–º –∞—Ä—Ç–∏–∫—É–ª –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞
                        article_patterns = [
                            r'—Ç–æ–≤-\d{6}',
                            r'–ê—Ä—Ç–∏–∫—É–ª[:\s]*—Ç–æ–≤-\d{6}',
                            r'–ö–æ–¥ —Ç–æ–≤–∞—Ä–∞[:\s]*—Ç–æ–≤-\d{6}'
                        ]
                        
                        page_text = product_soup.get_text()
                        for pattern in article_patterns:
                            matches = re.findall(pattern, page_text, re.IGNORECASE)
                            if matches:
                                found_article = matches[0].replace('–ê—Ä—Ç–∏–∫—É–ª:', '').replace('–ö–æ–¥ —Ç–æ–≤–∞—Ä–∞:', '').strip()
                                print(f"    –ù–∞–π–¥–µ–Ω –∞—Ä—Ç–∏–∫—É–ª: {found_article}")
                                
                                if found_article == article_with_prefix:
                                    print(f"    ‚úÖ –ù–ê–ô–î–ï–ù! {found_article}")
                                    return True
                    
                    time.sleep(0.5)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
                except Exception as e:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ú–µ—Ç–æ–¥–∞ 2: {e}")
    
    # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
    print(f"\nüéØ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ü–æ–∏—Å–∫ –ø–æ –ø–æ–ª–Ω–æ–º—É –∞—Ä—Ç–∏–∫—É–ª—É")
    print("-" * 30)
    
    full_search_url = f"https://saturn-r.ru/search/?q={article_with_prefix}"
    print(f"URL –ø–æ–∏—Å–∫–∞: {full_search_url}")
    
    try:
        response = session.get(full_search_url, timeout=10)
        print(f"–°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            product_containers = soup.find_all('div', class_='h_s_list_categor_item_wrap')
            print(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤: {len(product_containers)}")
            
            for i, container in enumerate(product_containers):
                article_elem = container.find('p', class_='h_s_list_categor_item_articul')
                name_elem = container.find('a', class_='h_s_list_categor_item')
                
                if article_elem and name_elem:
                    found_article = article_elem.get_text(strip=True)
                    found_name = name_elem.get_text(strip=True)
                    print(f"  {i+1}. {found_article}: {found_name}")
                    
                    if found_article == article_with_prefix:
                        print(f"  ‚úÖ –ù–ê–ô–î–ï–ù! {found_article}")
                        return True
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
    
    print(f"\n‚ùå –¢–û–í–ê–† {article_with_prefix} –ù–ï –ù–ê–ô–î–ï–ù –ù–ò–ö–ê–ö–ò–ú –ú–ï–¢–û–î–û–ú")
    return False

if __name__ == "__main__":
    debug_product_007556()

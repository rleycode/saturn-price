#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ü–µ–Ω —Å —Å–∞–π—Ç–∞ Saturn –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
"""

import requests
from bs4 import BeautifulSoup
import re
import time

def test_saturn_parsing():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—ã –¥–ª—è —Ç–æ–≤–∞—Ä–∞ —Ç–æ–≤-114289"""
    
    # –ê—Ä—Ç–∏–∫—É–ª –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
    article = "114289"
    
    # URL –ø–æ–∏—Å–∫–∞ –Ω–∞ Saturn
    search_url = f"https://nnv.saturn.net/catalog/?sp%5Bname%5D=1&sp%5Bartikul%5D=1&search=&s={article}"
    
    print(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª–∞: {article}")
    print(f"URL: {search_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print("\nüì° –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å...")
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω: {response.status_code}")
        print(f"–†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(response.content)} –±–∞–π—Ç")
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ü–µ–Ω
        print("\nüîç –ü–æ–∏—Å–∫ —Ü–µ–Ω —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏:")
        
        # 1. data-price –∞—Ç—Ä–∏–±—É—Ç—ã
        print("\n1Ô∏è‚É£ –ü–æ–∏—Å–∫ –ø–æ data-price:")
        price_elements = soup.find_all(attrs={'data-price': True})
        for elem in price_elements[:5]:  # –ü–µ—Ä–≤—ã–µ 5
            print(f"  data-price='{elem.get('data-price')}' –≤ —Ç–µ–≥–µ {elem.name}")
        
        # 2. –ö–ª–∞—Å—Å—ã —Å —Ü–µ–Ω–∞–º–∏
        print("\n2Ô∏è‚É£ –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º —Ü–µ–Ω:")
        price_classes = ['price', 'cost', 'amount', 'rub']
        for cls in price_classes:
            elements = soup.find_all(class_=re.compile(cls, re.I))
            for elem in elements[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
                text = elem.get_text(strip=True)
                if text and any(c.isdigit() for c in text):
                    print(f"  –ö–ª–∞—Å—Å '{cls}': {text}")
        
        # 3. –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É —Å —Ä—É–±–ª—è–º–∏
        print("\n3Ô∏è‚É£ –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ —Å —Ä—É–±–ª—è–º–∏:")
        rub_pattern = r'(\d+(?:[,.]?\d+)?)\s*(?:‚ÇΩ|—Ä—É–±|rub)'
        all_text = soup.get_text()
        rub_matches = re.findall(rub_pattern, all_text, re.IGNORECASE)
        unique_prices = list(set(rub_matches))[:10]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã
        for price in unique_prices:
            print(f"  –ù–∞–π–¥–µ–Ω–∞ —Ü–µ–Ω–∞: {price}‚ÇΩ")
        
        # 4. –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è Saturn
        print("\n4Ô∏è‚É£ –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ Saturn:")
        
        # –ü–æ–∏—Å–∫ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤
        product_cards = soup.find_all(['div', 'article'], class_=re.compile(r'product|item|card', re.I))
        print(f"  –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤: {len(product_cards)}")
        
        for i, card in enumerate(product_cards[:3]):
            print(f"\n  üì¶ –ö–∞—Ä—Ç–æ—á–∫–∞ {i+1}:")
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            title_elem = card.find(['h1', 'h2', 'h3', 'a'], class_=re.compile(r'title|name', re.I))
            if title_elem:
                title = title_elem.get_text(strip=True)
                print(f"    –ù–∞–∑–≤–∞–Ω–∏–µ: {title[:60]}...")
            
            # –ê—Ä—Ç–∏–∫—É–ª
            article_elem = card.find(text=re.compile(r'–∞—Ä—Ç–∏–∫—É–ª|–∞—Ä—Ç', re.I))
            if article_elem:
                print(f"    –ê—Ä—Ç–∏–∫—É–ª –Ω–∞–π–¥–µ–Ω: {article_elem.strip()}")
            
            # –¶–µ–Ω—ã –≤ –∫–∞—Ä—Ç–æ—á–∫–µ
            card_prices = card.find_all(attrs={'data-price': True})
            for price_elem in card_prices:
                print(f"    data-price: {price_elem.get('data-price')}")
            
            # –¢–µ–∫—Å—Ç —Å —Ü–µ–Ω–∞–º–∏
            card_text = card.get_text()
            card_rub_matches = re.findall(rub_pattern, card_text, re.IGNORECASE)
            for price in set(card_rub_matches):
                print(f"    –¶–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ: {price}‚ÇΩ")
        
        # 5. –ü–æ–∏—Å–∫ –ø–æ ID –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
        print("\n5Ô∏è‚É£ –ü–æ–∏—Å–∫ –ø–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º:")
        
        specific_selectors = [
            '[data-price]',
            '.price',
            '.cost', 
            '.amount',
            '#price',
            '[class*="price"]',
            '[class*="cost"]'
        ]
        
        for selector in specific_selectors:
            try:
                elements = soup.select(selector)
                if elements:
                    print(f"  –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}': {len(elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    for elem in elements[:2]:
                        text = elem.get_text(strip=True)
                        data_price = elem.get('data-price', '')
                        if text or data_price:
                            print(f"    –¢–µ–∫—Å—Ç: '{text}', data-price: '{data_price}'")
            except Exception as e:
                print(f"  –û—à–∏–±–∫–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ '{selector}': {e}")
        
        # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –≤ —Ñ–∞–π–ª...")
        with open('saturn_debug.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        print("  –§–∞–π–ª saturn_debug.html —Å–æ–∑–¥–∞–Ω")
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")

if __name__ == "__main__":
    test_saturn_parsing()

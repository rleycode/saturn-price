#!/usr/bin/env python3
"""
–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–∞—Ç–∞–ª–æ–≥–∞ Saturn –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å —Ç–æ–≤–∞—Ä–∞–º–∏
"""

import requests
from bs4 import BeautifulSoup
import time
from urllib.parse import urljoin
import logging

class SaturnCategoryExplorer:
    
    def __init__(self):
        self.base_url = "https://msk.saturn.net"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.logger = logging.getLogger(__name__)
        
    def explore_main_catalog(self):
        """–ò—Å—Å–ª–µ–¥—É–µ—Ç –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        
        try:
            url = f"{self.base_url}/catalog/"
            self.logger.info(f"–ò—Å—Å–ª–µ–¥—É–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞: {url}")
            
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_links = []
            
            # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            selectors = [
                'a[href*="/catalog/"]',
                '.category-link',
                '.menu-item a',
                '.catalog-menu a',
                'nav a[href*="/catalog/"]'
            ]
            
            for selector in selectors:
                links = soup.select(selector)
                for link in links:
                    href = link.get('href')
                    if href and '/catalog/' in href and href != '/catalog/':
                        full_url = urljoin(self.base_url, href)
                        text = link.get_text(strip=True)
                        if text and len(text) > 2:
                            category_links.append({
                                'url': full_url,
                                'text': text,
                                'selector': selector
                            })
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_categories = {}
            for cat in category_links:
                if cat['url'] not in unique_categories:
                    unique_categories[cat['url']] = cat
            
            self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_categories)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
            
            for cat in list(unique_categories.values())[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"üìÇ {cat['text']} - {cat['url']}")
            
            return list(unique_categories.values())
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return []
    
    def test_category_products(self, category_url: str, category_name: str):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–æ–≤"""
        
        try:
            self.logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category_name}")
            
            response = self.session.get(category_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã
            product_items = soup.find_all('div', class_='h_s_list_categor_item_wrap')
            
            if product_items:
                print(f"‚úÖ {category_name}: {len(product_items)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
                for i, item in enumerate(product_items[:3]):
                    article_elem = item.find('p', class_='h_s_list_categor_item_articul')
                    if article_elem:
                        article = article_elem.get_text(strip=True)
                        print(f"  {i+1}. {article}")
                
                return len(product_items)
            else:
                print(f"‚ùå {category_name}: —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return 0
                
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category_name}: {e}")
            return 0
    
    def find_pagination_urls(self, base_category_url: str):
        """–ò—â–µ—Ç URL –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        
        try:
            response = self.session.get(base_category_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò—â–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
            pagination_links = []
            
            # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
            pagination_selectors = [
                '.pagination a',
                '.pager a',
                'a[href*="PAGEN"]',
                '.page-numbers a'
            ]
            
            for selector in pagination_selectors:
                links = soup.select(selector)
                for link in links:
                    href = link.get('href')
                    if href:
                        full_url = urljoin(base_category_url, href)
                        pagination_links.append(full_url)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ URL –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
            for page in range(2, 11):  # –°—Ç—Ä–∞–Ω–∏—Ü—ã 2-10
                if 'PAGEN_1=' in base_category_url:
                    continue
                
                separator = '&' if '?' in base_category_url else '?'
                page_url = f"{base_category_url}{separator}PAGEN_1={page}"
                pagination_links.append(page_url)
            
            return list(set(pagination_links))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: {e}")
            return []

def main():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    explorer = SaturnCategoryExplorer()
    
    print("üîç –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –ö–ê–¢–ê–õ–û–ì–ê SATURN")
    print("="*50)
    
    # –ò—Å—Å–ª–µ–¥—É–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞
    categories = explorer.explore_main_catalog()
    
    if not categories:
        print("‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ URL")
        
        # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ URL
        test_urls = [
            "https://msk.saturn.net/catalog/elektronika/",
            "https://msk.saturn.net/catalog/bytovaya-tekhnika/",
            "https://msk.saturn.net/catalog/kompyutery/",
            "https://msk.saturn.net/catalog/telefony/",
            "https://msk.saturn.net/catalog/audio-video/",
        ]
        
        for url in test_urls:
            count = explorer.test_category_products(url, url.split('/')[-2])
            time.sleep(1)
    else:
        print(f"\nüìä –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ô ({len(categories)} –Ω–∞–π–¥–µ–Ω–æ)")
        print("="*50)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        for category in categories[:5]:
            count = explorer.test_category_products(category['url'], category['text'])
            
            if count > 0:
                # –ò—â–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                pagination_urls = explorer.find_pagination_urls(category['url'])
                if pagination_urls:
                    print(f"  üìÑ –ù–∞–π–¥–µ–Ω–æ {len(pagination_urls)} —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏")
            
            time.sleep(1)
    
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("- –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —Ç–æ–≤–∞—Ä–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Ö URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    print("- –î–æ–±–∞–≤—å—Ç–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ URL –≤ catalog_crawler.py")
    print("- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞–≥–∏–Ω–∞—Ü–∏—é –¥–ª—è –æ–±—Ö–æ–¥–∞ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

if __name__ == "__main__":
    main()

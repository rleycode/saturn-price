#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ —Ç–æ–≤-114289 –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö Saturn
"""

import requests
from bs4 import BeautifulSoup
import re
import json

def find_specific_product():
    """–ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä —Ç–æ–≤-114289"""
    
    article = "114289"
    search_url = f"https://nnv.saturn.net/catalog/?sp%5Bname%5D=1&sp%5Bartikul%5D=1&search=&s={article}"
    
    print(f"üîç –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–∞ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º: {article}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä: {len(response.content)} –±–∞–π—Ç")
        
        # –ò—â–µ–º —Ç–æ–≤–∞—Ä –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é "–ë—Ä—É—Å–æ–∫ —Å—É—Ö–æ–π —Å—Ç—Ä–æ–≥–∞–Ω—ã–π"
        target_keywords = ["–±—Ä—É—Å–æ–∫", "—Å—É—Ö–æ–π", "—Å—Ç—Ä–æ–≥–∞–Ω—ã–π", "18", "20", "30", "3000"]
        
        print(f"\nüéØ –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {target_keywords}")
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
        product_links = soup.find_all('a', href=re.compile(r'/catalog/.*'))
        
        print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã: {len(product_links)}")
        
        candidates = []
        
        for link in product_links:
            link_text = link.get_text(strip=True).lower()
            href = link.get('href', '')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            matches = sum(1 for keyword in target_keywords if keyword in link_text)
            
            if matches >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                candidates.append({
                    'text': link.get_text(strip=True),
                    'href': href,
                    'matches': matches,
                    'element': link
                })
        
        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        candidates.sort(key=lambda x: x['matches'], reverse=True)
        
        for i, candidate in enumerate(candidates[:5]):
            print(f"\nüèÜ –ö–∞–Ω–¥–∏–¥–∞—Ç {i+1} (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {candidate['matches']}):")
            print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {candidate['text']}")
            print(f"  –°—Å—ã–ª–∫–∞: {candidate['href']}")
            
            # –ò—â–µ–º —Ü–µ–Ω—É —Ä—è–¥–æ–º —Å —ç—Ç–∏–º —Ç–æ–≤–∞—Ä–æ–º
            parent = candidate['element'].parent
            if parent:
                # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
                price_elements = parent.find_all(attrs={'data-price': True})
                for price_elem in price_elements:
                    price_value = price_elem.get('data-price')
                    print(f"  üí∞ –¶–µ–Ω–∞ data-price: {price_value}")
                
                # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ
                parent_text = parent.get_text()
                rub_pattern = r'(\d+(?:[,.]?\d+)?)\s*(?:‚ÇΩ|—Ä—É–±)'
                prices_in_text = re.findall(rub_pattern, parent_text, re.IGNORECASE)
                for price in set(prices_in_text):
                    print(f"  üí∞ –¶–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ: {price}‚ÇΩ")
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫: –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –≤ —Ç–µ–∫—Å—Ç–µ
        print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É {article} –≤ —Ç–µ–∫—Å—Ç–µ:")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ü–µ–Ω
        rub_pattern = r'(\d+(?:[,.]?\d+)?)\s*(?:‚ÇΩ|—Ä—É–±)'
        
        # –ò—â–µ–º –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∞—Ä—Ç–∏–∫—É–ª–∞
        article_pattern = rf'\b{article}\b'
        page_text = soup.get_text()
        
        if re.search(article_pattern, page_text):
            print(f"  ‚úÖ –ê—Ä—Ç–∏–∫—É–ª {article} –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ!")
            
            # –ò—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∞—Ä—Ç–∏–∫—É–ª–∞
            lines = page_text.split('\n')
            for i, line in enumerate(lines):
                if re.search(article_pattern, line):
                    print(f"  üìç –°—Ç—Ä–æ–∫–∞ {i}: {line.strip()}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω
                    context_lines = lines[max(0, i-3):i+4]
                    for j, context_line in enumerate(context_lines):
                        prices = re.findall(rub_pattern, context_line, re.IGNORECASE)
                        if prices:
                            print(f"    üí∞ –¶–µ–Ω–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {prices}")
        else:
            print(f"  ‚ùå –ê—Ä—Ç–∏–∫—É–ª {article} –ù–ï –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–≤–∞—Ä –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        print(f"\nüîç –ü–æ–∏—Å–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∞—Ä—Ç–∏–∫—É–ª–∞:")
        
        alt_formats = [
            f"—Ç–æ–≤-{article}",
            f"—Ç–æ–≤ {article}",
            f"–∞—Ä—Ç. {article}",
            f"–∞—Ä—Ç–∏–∫—É–ª {article}",
            f"#{article}"
        ]
        
        for alt_format in alt_formats:
            if alt_format.lower() in page_text.lower():
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–æ—Ä–º–∞—Ç: {alt_format}")
            else:
                print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω: {alt_format}")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä
        print(f"\nüéØ –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä...")
        
        # –ü–æ–∏—Å–∫ –≤ JSON –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string and article in script.string:
                print(f"  ‚úÖ –ê—Ä—Ç–∏–∫—É–ª –Ω–∞–π–¥–µ–Ω –≤ JavaScript!")
                # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å JSON
                try:
                    # –ò—â–µ–º JSON —Å —Ç–æ–≤–∞—Ä–∞–º–∏
                    json_match = re.search(r'(\{.*"' + article + r'".*\})', script.string)
                    if json_match:
                        print(f"  üìä JSON –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã")
                except:
                    pass
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    find_specific_product()

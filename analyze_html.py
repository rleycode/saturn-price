#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
"""

import os
from bs4 import BeautifulSoup
import re

def analyze_html_file(filename):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTML —Ñ–∞–π–ª –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤"""
    
    if not os.path.exists(filename):
        print(f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {filename}")
    print("="*50)
    
    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    soup = BeautifulSoup(content, 'html.parser')
    
    # 1. –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–ª–∞—Å—Å—ã —Ç–æ–≤–∞—Ä–æ–≤
    possible_item_classes = [
        'catalog-item', 'product-item', 'item', 'product', 
        'goods-item', 'card', 'product-card', 'catalog-card'
    ]
    
    for class_name in possible_item_classes:
        items = soup.find_all('div', class_=class_name)
        if items:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–∞—Å—Å–æ–º '{class_name}'")
    
    # 2. –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
    print(f"\nüè∑Ô∏è –ü–æ–∏—Å–∫ –∞—Ä—Ç–∏–∫—É–ª–æ–≤:")
    
    # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —á–∏—Å–ª–∞ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã)
    all_text = soup.get_text()
    article_patterns = [
        r'—Ç–æ–≤-\d+',
        r'\d{6}',  # 6-–∑–Ω–∞—á–Ω—ã–µ —á–∏—Å–ª–∞
        r'–∞—Ä—Ç–∏–∫—É–ª[:\s]*(\d+)',
        r'–∫–æ–¥[:\s]*(\d+)'
    ]
    
    for pattern in article_patterns:
        matches = re.findall(pattern, all_text, re.IGNORECASE)
        if matches:
            print(f"  üìç –ü–∞—Ç—Ç–µ—Ä–Ω '{pattern}': –Ω–∞–π–¥–µ–Ω–æ {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
            for match in matches[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"    - {match}")
    
    # 3. –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–µ–Ω–∞–º–∏
    print(f"\nüí∞ –ü–æ–∏—Å–∫ —Ü–µ–Ω:")
    
    price_patterns = [
        r'\d+[,.]?\d*\s*—Ä—É–±',
        r'\d+[,.]?\d*\s*‚ÇΩ',
        r'data-price="(\d+)"',
        r'price["\s:]*(\d+)'
    ]
    
    for pattern in price_patterns:
        matches = re.findall(pattern, all_text, re.IGNORECASE)
        if matches:
            print(f"  üíµ –ü–∞—Ç—Ç–µ—Ä–Ω '{pattern}': –Ω–∞–π–¥–µ–Ω–æ {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    # 4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    print(f"\nüìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
    
    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
    containers = [
        ('main', 'main'),
        ('content', 'div'),
        ('catalog', 'div'),
        ('products', 'div'),
        ('results', 'div')
    ]
    
    for class_name, tag in containers:
        elements = soup.find_all(tag, class_=lambda x: x and class_name in x.lower() if x else False)
        if elements:
            print(f"  üì¶ {tag}.{class_name}: {len(elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    
    # 5. –ò—â–µ–º JavaScript –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–≤–∞—Ä—ã
    print(f"\nüîß JavaScript –∞–Ω–∞–ª–∏–∑:")
    
    scripts = soup.find_all('script')
    js_keywords = ['ajax', 'fetch', 'catalog', 'products', 'load']
    
    for keyword in js_keywords:
        count = sum(1 for script in scripts if script.string and keyword in script.string.lower())
        if count > 0:
            print(f"  ‚öôÔ∏è –°–∫—Ä–∏–ø—Ç–æ–≤ —Å '{keyword}': {count}")
    
    # 6. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ä–º –ø–æ–∏—Å–∫–∞
    print(f"\nüîç –§–æ—Ä–º—ã –ø–æ–∏—Å–∫–∞:")
    
    forms = soup.find_all('form')
    search_forms = [form for form in forms if form.get('action') and 'search' in form.get('action', '').lower()]
    
    if search_forms:
        print(f"  üìù –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ä–º –ø–æ–∏—Å–∫–∞: {len(search_forms)}")
        for form in search_forms:
            print(f"    - Action: {form.get('action')}")
    
    # 7. –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—É—Å—Ç—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    print(f"\n‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    
    empty_messages = [
        '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ', '–Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤', '–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
        'no results', 'not found', '–ø—É—Å—Ç–æ', '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'
    ]
    
    for message in empty_messages:
        if message in all_text.lower():
            print(f"  üö´ –ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: '{message}'")

def main():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã"""
    
    html_files = [f for f in os.listdir('.') if f.startswith('debug_search_') and f.endswith('.html')]
    
    if not html_files:
        print("‚ùå HTML —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ HTML —Ñ–∞–π–ª–æ–≤: {len(html_files)}")
    
    for html_file in html_files[:2]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 2 —Ñ–∞–π–ª–∞
        analyze_html_file(html_file)

if __name__ == "__main__":
    main()
